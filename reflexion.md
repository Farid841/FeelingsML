## **Contexte du projet**  
Nous travaillons pour **SocialMetrics AI**, une entreprise fictive spÃ©cialisÃ©e dans lâ€™analyse des donnÃ©es issues des rÃ©seaux sociaux. Notre client, **Daunale Treupe**, souhaite mettre en place un service permettant dâ€™Ã©valuer le sentiment des tweets en fonction de leur contenu.  

### **Objectifs du projet**  
1. DÃ©velopper une **API Flask** pour traiter les tweets en temps rÃ©el et renvoyer une analyse de sentiment (positif ou nÃ©gatif).  
2. Utiliser un **modÃ¨le de machine learning basÃ© sur la rÃ©gression logistique** pour effectuer ces prÃ©dictions.  
3. **RÃ©entraÃ®ner rÃ©guliÃ¨rement** le modÃ¨le avec de nouvelles donnÃ©es pour amÃ©liorer sa prÃ©cision au fil du temps.  
4. Ã‰valuer la performance du modÃ¨le Ã  lâ€™aide dâ€™**indicateurs clÃ©s** (prÃ©cision, rappel, F1-score) et de **matrices de confusion**.  


## **Acquisition des donnÃ©es**  
Lâ€™entraÃ®nement dâ€™un bon modÃ¨le nÃ©cessite une **grande quantitÃ© de donnÃ©es** pour quâ€™il puisse apprendre efficacement. Nous avons rÃ©cupÃ©rÃ© **environ 80 000 tweets** grÃ¢ce Ã  **Kaggle** (merci Kaggle de nous avoir facilitÃ© cette Ã©tape !) :  
- **40 000 tweets** provenant de Twitter  
- **40 000 commentaires** issus de Reddit  

Ces donnÃ©es nous serviront Ã  entraÃ®ner et tester notre modÃ¨le dâ€™analyse de sentiment.  

### **Utilisation progressive des donnÃ©es**  
Pour la **premiÃ¨re vague de tests**, nous allons utiliser **40 000 tweets uniquement**, afin dâ€™avoir une base de dÃ©part sans surcharge de calcul. Lâ€™idÃ©e est dâ€™utiliser **seulement 1/40k** pour faire des premiers tests et valider la faisabilitÃ© du modÃ¨le avant de lâ€™affiner avec plus de donnÃ©es.  


## **Pourquoi bien diviser les donnÃ©es ?**  
Un bon modÃ¨le dâ€™IA repose dâ€™abord sur **beaucoup de donnÃ©es dâ€™entraÃ®nement**, mais ce nâ€™est pas suffisant. Il faut aussi sâ€™assurer quâ€™il **gÃ©nÃ©ralise bien** et ne se contente pas de "mÃ©moriser" les tweets quâ€™il a dÃ©jÃ  vus. Câ€™est lÃ  quâ€™intervient la division des donnÃ©es.  

### **Nettoyage des donnÃ©es**  
Avant de les utiliser, les donnÃ©es doivent Ãªtre **nettoyÃ©es** pour supprimer :  
âœ… **Les mots inutiles** (a, the, andâ€¦) qui nâ€™apportent rien au sens global du tweet.  
âœ… **Les caractÃ¨res spÃ©ciaux**, les hashtags, les emojis, et autres Ã©lÃ©ments qui peuvent biaiser lâ€™analyse.  
âœ… **Les doublons**, afin dâ€™Ã©viter que le modÃ¨le surapprenne certaines expressions trop prÃ©sentes.  

### **Pourquoi diviser les donnÃ©es en plusieurs ensembles ?**  
La division des donnÃ©es en plusieurs groupes permet de :  

1ï¸âƒ£ **EntraÃ®ner le modÃ¨le** :  
- Le modÃ¨le apprend les **motifs et structures des tweets** pour diffÃ©rencier les sentiments positifs et nÃ©gatifs.  
- Ex : Un tweet comme *"J'adore cette journÃ©e ! ğŸ˜Š"* sera Ã©tiquetÃ© **positif**, et un tweet comme *"Cette journÃ©e est horrible ğŸ˜¡"* sera **nÃ©gatif**.  

2ï¸âƒ£ **Ã‰valuer le modÃ¨le** :  
- AprÃ¨s l'entraÃ®nement, il faut tester le modÃ¨le sur des tweets **qu'il n'a jamais vus** pour vÃ©rifier qu'il ne fait pas dâ€™erreurs.  
- Ex : Si on donne le tweet *"Ce produit est trop cher pour sa qualitÃ©"* et que le modÃ¨le le classe **positif**, cela signifie quâ€™il ne comprend pas bien le contexte.  

3ï¸âƒ£ **Ã‰viter le surapprentissage (overfitting)** :  
- Si on entraÃ®ne le modÃ¨le **uniquement sur les tweets quâ€™il connaÃ®t**, il risque dâ€™apprendre "par cÅ“ur" au lieu de **comprendre rÃ©ellement**.  
- Ex : Un Ã©tudiant qui mÃ©morise toutes les rÃ©ponses dâ€™un examen dâ€™entraÃ®nement mais qui Ã©choue quand on lui pose une nouvelle question.  


## **Comment diviser les donnÃ©es ?**  
Pour entraÃ®ner et tester notre modÃ¨le, nous devons diviser notre dataset en **plusieurs ensembles** :  
ğŸ”¹ **DonnÃ©es dâ€™entraÃ®nement** (Training set) : utilisÃ©es pour apprendre.  
ğŸ”¹ **DonnÃ©es de test** (Test set) : utilisÃ©es pour Ã©valuer le modÃ¨le.  
ğŸ”¹ **DonnÃ©es pour le rÃ©entraÃ®nement** : utilisÃ©es plus tard pour amÃ©liorer le modÃ¨le.  

### **Choix du pourcentage de division**  
Il existe plusieurs stratÃ©gies de rÃ©partition des donnÃ©es , chacune avec ses avantages et inconvÃ©nients. 


### **1ï¸âƒ£ 70% entraÃ®nement / 30% test** (*mÃ©thode classique*)
---
ğŸ“Œ **Principe** :  
- 70% des tweets servent Ã  entraÃ®ner le modÃ¨le.  
- 30% sont gardÃ©s pour tester sa performance.  

âœ… **Avantages** :  
âœ” Bonne rÃ©partition entre apprentissage et Ã©valuation.  
âœ” Permet une estimation fiable des performances du modÃ¨le.  
âœ” Convient aux datasets de taille moyenne.  

âŒ **InconvÃ©nients** :  
âœ˜ Peut Ãªtre insuffisant pour un entraÃ®nement optimal si le dataset est trop petit.  
âœ˜ Une rÃ©partition fixe ne prend pas en compte les Ã©volutions des donnÃ©es.  

ğŸ” **Exemple** :  
Imaginons un modÃ¨le de classification de sentiments sur Twitter. Si nous avons **10 000 tweets**, alors **7 000** serviront Ã  entraÃ®ner le modÃ¨le et **3 000** Ã  le tester. Si les tendances sur Twitter changent rapidement, les **30% de test peuvent devenir obsolÃ¨tes** aprÃ¨s un certain temps.  


### **2ï¸âƒ£ 80% entraÃ®nement / 20% test** (*si on a beaucoup de donnÃ©es*)  
---
ğŸ“Œ **Principe** :  
- On maximise lâ€™apprentissage (80%).  
- On garde un test fiable (20%).  

âœ… **Avantages** :  
âœ” Plus de donnÃ©es pour lâ€™apprentissage, donc un modÃ¨le potentiellement plus performant.  
âœ” Toujours une bonne Ã©valuation avec 20% de test.  

âŒ **InconvÃ©nients** :  
âœ˜ Moins de donnÃ©es pour tester peut donner une Ã©valuation lÃ©gÃ¨rement moins prÃ©cise.  
âœ˜ Risque de surentraÃ®nement (overfitting) si les 80% sont trop homogÃ¨nes.  

ğŸ” **Exemple** :  
Si nous avons **100 000 tweets**, **80 000** seront utilisÃ©s pour entraÃ®ner le modÃ¨le et **20 000** pour lâ€™Ã©valuer. Cette approche est particuliÃ¨rement utile si nous avons des donnÃ©es variÃ©es et en grande quantitÃ©.  


### **3ï¸âƒ£ 90% entraÃ®nement / 10% test** (*optimisation maximale de lâ€™apprentissage*)  
---
ğŸ“Œ **Principe** :  
- 90% des donnÃ©es pour entraÃ®ner le modÃ¨le.  
- 10% seulement pour Ã©valuer.  

âœ… **Avantages** :  
âœ” IdÃ©al si on a un grand dataset et quâ€™on veut maximiser lâ€™apprentissage.  
âœ” Peut amÃ©liorer la prÃ©cision du modÃ¨le sur de nouvelles donnÃ©es.  

âŒ **InconvÃ©nients** :  
âœ˜ Peu de donnÃ©es pour tester â†’ risque dâ€™une Ã©valuation peu fiable.  
âœ˜ Risque dâ€™overfitting car le modÃ¨le est trop optimisÃ© pour lâ€™ensemble dâ€™entraÃ®nement.  

ğŸ” **Exemple** :  
Si nous avons **1 million de tweets**, nous utilisons **900 000** pour lâ€™entraÃ®nement et seulement **100 000** pour le test. Cela permet dâ€™entraÃ®ner un modÃ¨le puissant, mais nous avons moins de recul sur ses performances rÃ©elles.  


### **4ï¸âƒ£ 66% entraÃ®nement / 33% pour rÃ©entraÃ®nement** (*notre choix*)  
---
ğŸ“Œ **Principe** :  
- 66% des donnÃ©es pour lâ€™entraÃ®nement initial.  
- 33% des donnÃ©es mises de cÃ´tÃ© pour Ãªtre utilisÃ©es plus tard comme nouvelles donnÃ©es de rÃ©entraÃ®nement.  

âœ… **Avantages** :  
âœ” Permet dâ€™entraÃ®ner le modÃ¨le sur des donnÃ©es rÃ©centes.  
âœ” Offre la possibilitÃ© de rÃ©entraÃ®nement avec des nouvelles donnÃ©es au fil du temps.  
âœ” Sâ€™adapte aux tendances changeantes (ex. nouvelles expressions sur Twitter).  

âŒ **InconvÃ©nients** :  
âœ˜ Au dÃ©part, on teste avec les mÃªmes donnÃ©es dâ€™entraÃ®nement.  
âœ˜ On doit attendre pour utiliser les donnÃ©es mises de cÃ´tÃ©, ce qui peut ralentir lâ€™amÃ©lioration immÃ©diate du modÃ¨le.  

ğŸ” **Exemple** :  
- On **cache 10 000 tweets**comme s'ils n'existaient pas.
- On utilise les **30 000 tweets restants** pour entraÃ®ner et valider le modÃ¨le.
- Une fois satisfait, on **rÃ©intÃ¨gre les 10 000 tweets cachÃ©s** pour tester si le modÃ¨le gÃ©nÃ©ralise bien sur ces nouvelles donnÃ©es.


### **5ï¸âƒ£ Validation croisÃ©e (Cross-Validation)**  
---
En plus de la division classique, nous pouvons utiliser une **validation croisÃ©e** pour mieux Ã©valuer notre modÃ¨le.  

ğŸ“Œ **Principe** :  
On divise les donnÃ©es en plusieurs **sous-ensembles** et on entraÃ®ne plusieurs modÃ¨les en utilisant chaque sous-ensemble comme test Ã  tour de rÃ´le.  

âœ… **Avantages** :  
âœ” Permet une meilleure Ã©valuation du modÃ¨le en utilisant toutes les donnÃ©es.  
âœ” RÃ©duit les biais de division fixe (ex. si les donnÃ©es sont mal rÃ©parties).  
âœ” Utile surtout pour les petits datasets.  

âŒ **InconvÃ©nients** :  
âœ˜ Plus coÃ»teux en calculs â†’ prend plus de temps.  
âœ˜ Pas toujours nÃ©cessaire si on a beaucoup de donnÃ©es.  

ğŸ” **Exemple** :  
Avec une validation croisÃ©e **5-fold**, on divise les **10 000 tweets** en **5 groupes de 2 000 tweets**. On entraÃ®ne 5 modÃ¨les, chacun utilisant 4 groupes pour lâ€™entraÃ®nement et 1 groupe pour le test, puis on fait la moyenne des performances.  
 

### **tableau recapitulatif : quel choix adopter ?**  

| MÃ©thode                  | Avantages | InconvÃ©nients | IdÃ©al pour |
|-------------------------|-----------|--------------|------------|
| **70% entraÃ®nement / 30% test** | Bon Ã©quilibre entre apprentissage et test | Risque de ne pas capturer les Ã©volutions des donnÃ©es | Datasets moyens |
| **80% entraÃ®nement / 20% test** | Plus dâ€™apprentissage sans trop rÃ©duire lâ€™Ã©valuation | LÃ©gÃ¨rement moins fiable pour le test | Datasets volumineux |
| **90% entraÃ®nement / 10% test** | Maximisation de lâ€™apprentissage | Test moins fiable, risque dâ€™overfitting | TrÃ¨s grands datasets |
| **66% entraÃ®nement / 33% rÃ©entraÃ®nement** | Permet une adaptation continue du modÃ¨le | NÃ©cessite un suivi rÃ©gulier | ModÃ¨les Ã©volutifs (ex. Twitter) |
| **Validation croisÃ©e** | Meilleure Ã©valuation | Plus long Ã  calculer | Petits datasets |

ğŸš€ **Dans notre cas, nous avons choisi la rÃ©partition 66% / 33%** pour garantir un modÃ¨le qui **sâ€™amÃ©liore dans le temps** et suit les Ã©volutions du langage sur Twitter.


## **Explication du fichier `load_data.py`**

Le fichier `load_data.py` est responsable du **chargement, du nettoyage et de l'insertion des tweets dans la base de donnÃ©es MySQL**. Avant d'entraÃ®ner notre modÃ¨le, nous devons nous assurer que les donnÃ©es sont correctement structurÃ©es et prÃªtes Ã  Ãªtre exploitÃ©es.

### **ğŸ“Œ Ã‰tapes rÃ©alisÃ©es dans `load_data.py` :**

1ï¸âƒ£ **Chargement des donnÃ©es brutes** ğŸ”„
- Le fichier CSV `Twitter_Data.csv`, situÃ© dans le dossier `dataset/`, est chargÃ© avec **Pandas** (l'outil qui facilite la manipulation des donnÃ©es... contrairement Ã  JavaScript qui prÃ©fÃ¨re les transformer en chaos ğŸ¤¡ t'es pas d'accord ? 

```js
  console.log('5' + 5); // RÃ©sultat : '55' ğŸ˜µâ€ğŸ’«
  console.log('5' - 5); // RÃ©sultat : 0 ğŸ¤¯
  ```
bref..).

2ï¸âƒ£ **Nettoyage des donnÃ©es** ğŸ§¹
- Suppression des lignes contenant des valeurs `NaN`.
- Conversion des colonnes catÃ©goriques :
  - La colonne `category` contient une valeur unique (-1 pour nÃ©gatif, 0 pour neutre, 1 pour positif).
  - La base de donnÃ©es MySQL a **deux colonnes distinctes** (`positive` et `negative`), donc nous devons transformer `category` en ce format binaire.

3ï¸âƒ£ **SÃ©paration des donnÃ©es en deux ensembles** ğŸ“Š
- **66% des donnÃ©es** sont insÃ©rÃ©es immÃ©diatement dans la base MySQL pour entraÃ®ner le modÃ¨le.
- **33% des donnÃ©es** sont mises de cÃ´tÃ© dans `dataset/retrain_tweets.csv` pour amÃ©liorer le modÃ¨le plus tard.

4ï¸âƒ£ **Insertion dans MySQL** ğŸ—„ï¸
- Connexion Ã  la base de donnÃ©es.
- Insertion des donnÃ©es nettoyÃ©es dans la table `tweets`.
- Enregistrement des donnÃ©es restantes pour un rÃ©entraÃ®nement futur.

ğŸ“Œ **Visualisation du traitement des donnÃ©es :**
![RÃ©sultat du script `load_data.py`](/assets/output_load_data.png)


## **Optimisation de la base de donnÃ©es** ğŸš€

Pour accÃ©lÃ©rer les recherches et optimiser l'accÃ¨s aux donnÃ©es, nous avons **ajoutÃ© des index** dans notre modÃ¨le et dans le script de migration SQL (`init.sql`).

ğŸ“Œ **AmÃ©liorations apportÃ©es :**
- **Indexation de la colonne `text`** ğŸ“œ pour accÃ©lÃ©rer les recherches textuelles.
- **Indexation des colonnes `positive` et `negative`** âœ…âŒ pour optimiser les requÃªtes filtrant les sentiments.

Ces optimisations permettent Ã  l'API d'Ãªtre **plus rapide et plus efficace** lors de l'analyse des sentiments.


## **Relation entre le script d'entraÃ®nement et l'API Flask** ğŸ”„

Nous avons identifiÃ© une relation directe entre le **script d'entraÃ®nement** (`train_initial_model.py`) et l'**endpoint `/analyze`** de l'API Flask.

### ğŸ“Œ **Le script d'entraÃ®nement (`train_initial_model.py`) :**
- ğŸ“¥ **Charge les tweets annotÃ©s** depuis MySQL.
- ğŸ¯ **EntraÃ®ne un modÃ¨le de rÃ©gression logistique** pour classer les tweets en positifs et nÃ©gatifs.
- ğŸ’¾ **Sauvegarde le modÃ¨le et le vectorizer** pour Ãªtre utilisÃ© plus tard par l'API.

### ğŸ“Œ **L'endpoint `/analyze` dans Flask :**
- ğŸ“‚ **Charge le modÃ¨le prÃ©-entraÃ®nÃ©** depuis les fichiers sauvegardÃ©s.
- ğŸ”¢ **Transforme les tweets en vecteurs numÃ©riques** avec `vectorizer`.
- ğŸ” **Effectue une prÃ©diction** du sentiment pour chaque tweet.
- ğŸ“¤ **Retourne les rÃ©sultats au format JSON**.

GrÃ¢ce Ã  cette architecture, nous pouvons **analyser des tweets en temps rÃ©el** avec un modÃ¨le mis Ã  jour rÃ©guliÃ¨rement.

---

## **AmÃ©lioration du schÃ©ma de la base de donnÃ©es** ğŸ› ï¸

Afin d'Ã©viter des pertes de donnÃ©es et d'amÃ©liorer la visibilitÃ©, nous avons **modifiÃ© le schÃ©ma de la base de donnÃ©es** :

âœ… **Ajout d'une table `data_log`** pour stocker toutes les entrÃ©es et sorties du modÃ¨le.  
âœ… **Ajout d'une gestion des transactions** pour permettre un **rollback** en cas d'erreur lors d'un entraÃ®nement.
âœ… **Meilleure gestion des logs** pour tracer **quand** et **comment** les donnÃ©es ont Ã©tÃ© utilisÃ©es.

GrÃ¢ce Ã  ces amÃ©liorations, notre base de donnÃ©es devient **plus robuste**, ce qui permet de garantir un suivi des modifications et une meilleure fiabilitÃ© du modÃ¨le.

## Explication du script `train_model.py`

### **ğŸš€ Objectif du script**
Le script `train_model.py` est conÃ§u pour **entraÃ®ner un modÃ¨le de machine learning** capable d'analyser le sentiment des tweets enregistrÃ©s en base de donnÃ©es. Cependant, Ã©tant donnÃ© la grande quantitÃ© de donnÃ©es (~120K tweets), **il est optimisÃ© pour fonctionner par petits lots (batches)** afin de **prÃ©server la mÃ©moire et Ã©viter le crash de la machine (c'est ce qui m'est arrivÃ© )**.

### **ğŸ”§ FonctionnalitÃ©s principales**
âœ… Chargement des donnÃ©es depuis MySQL **par petits paquets (batch processing)**
âœ… Nettoyage des tweets **au fur et Ã  mesure** (pas de chargement massif en mÃ©moire)
âœ… Vectorisation des tweets avec **TF-IDF** sur chaque batch
âœ… EntraÃ®nement du modÃ¨le par **mini-batchs** pour limiter lâ€™utilisation de RAM
âœ… Reprise automatique en cas dâ€™arrÃªt (enregistre le dernier tweet traitÃ©)
âœ… Sauvegarde des modÃ¨les entraÃ®nÃ©s pour les rÃ©utiliser plus tard


### **ğŸ“‚ Ã‰tapes dÃ©taillÃ©es du script**

#### **1ï¸âƒ£ Chargement des tweets en petits paquets (batch processing)**
PlutÃ´t que de charger **120K tweets d'un coup**, le script :
- RÃ©cupÃ¨re **un petit lot de tweets (ex: 5000)** Ã  la fois depuis MySQL.
- Utilise lâ€™ID ou la date du dernier tweet traitÃ© pour reprendre lÃ  oÃ¹ il s'Ã©tait arrÃªtÃ©.

#### **2ï¸âƒ£ Nettoyage et vectorisation des donnÃ©es Ã  la volÃ©e**
Chaque lot de tweets est immÃ©diatement :
- NettoyÃ© (**passÃ© en minuscules, suppression des espaces, etc.**)
- Converti en vecteurs numÃ©riques avec **TF-IDF** (**max_features=2000** pour limiter la mÃ©moire)
- PrÃ©parÃ© pour lâ€™entraÃ®nement **sans Ãªtre stockÃ© en mÃ©moire**

#### **3ï¸âƒ£ EntraÃ®nement du modÃ¨le avec mini-batchs**
- Chaque batch de tweets est traitÃ© **indÃ©pendamment**
- Lâ€™entraÃ®nement se fait **progressivement** avec `warm_start=True`
- Utilisation de `solver='saga'` pour permettre un **entraÃ®nement en mini-batchs**

#### **4ï¸âƒ£ Reprise automatique aprÃ¨s arrÃªt**
- Le script enregistre le **dernier tweet traitÃ©** dans un fichier `last_processed.txt`
- Si le script est interrompu, il reprend Ã  partir du dernier tweet sans recommencer depuis le dÃ©but

#### **5ï¸âƒ£ Sauvegarde des modÃ¨les aprÃ¨s chaque batch**
- Les modÃ¨les sont enregistrÃ©s **aprÃ¨s chaque lot traitÃ©** pour Ã©viter toute perte
- Sauvegarde dans `models/logistic_regression_positive.pkl` et `models/logistic_regression_negative.pkl`

---

### **ğŸ”„ Optimisation : Mini-batchs et gestion de la mÃ©moire**

| ğŸ”§ ProblÃ¨me | ğŸš€ Solution |
|------------|------------|
| **Trop de tweets chargÃ©s en mÃ©moire** | Chargement en **batches de 5000 tweets** |
| **Vectorisation trop lourde** | RÃ©duction des features **(max_features=2000)** |
| **CPU surchargÃ©** | Mini-batchs avec `solver='saga'` et `n_jobs=1` |
| **RAM saturÃ©e** | EntraÃ®nement **progressif avec warm_start=True** |
| **Script qui redÃ©marre de zÃ©ro** | Reprise **depuis le dernier tweet traitÃ©** |

---

### **ğŸ“Œ ExÃ©cution du script**

### **ğŸ’¡ Avant de lancer l'entraÃ®nement**
1. VÃ©rifier si des donnÃ©es existent en base de donnÃ©es :
   ```sql
   SELECT COUNT(*) FROM tweet;
   ```
   Si `0`, exÃ©cuter d'abord `load_data.py` pour ajouter des tweets.

2. Modifier la taille du batch (optionnel) :
   Dans le script, changer cette ligne :
   ```python
   BATCH_SIZE = 5000  # Augmenter ou rÃ©duire selon les performances
   ```

### **ğŸš€ Lancer l'entraÃ®nement du modÃ¨le**
```bash
python3 train_model.py
```

### **ğŸ“Š VÃ©rifier les modÃ¨les sauvegardÃ©s**
AprÃ¨s l'entraÃ®nement, vÃ©rifier que les fichiers sont bien crÃ©Ã©s :
```bash
ls models/
```
Devrait afficher :
```
logistic_regression_positive.pkl
logistic_regression_negative.pkl
```
matrice de confusion  positive
![Matrix de confusion positive `load_data.py`](/outputs/confusion_matrix_positive_20250221.png)

matrix de confusion negative:
![Matrix de confusion positive `load_data.py`](/outputs/confusion_matrix_negative_20250221.png)

