import pandas as pd
import mysql.connector
from sklearn.model_selection import train_test_split

# Charger le CSV
df = pd.read_csv("dataset/Twitter_Data.csv")

# VÃ©rifier les premiÃ¨res lignes
print(df.head())

# Mapper les catÃ©gories en colonnes binaires
df['positive'] = df['category'].apply(lambda x: 1 if x == 1 else 0)
df['negative'] = df['category'].apply(lambda x: 1 if x == -1 else 0)

# ğŸ”¹ **SÃ©parer les tweets valides et ceux contenant des NaN**
df_valid = df.dropna()
df_invalid = df[df.isna().any(axis=1)]  # SÃ©lectionne les lignes qui contiennent au moins un NaN

# ğŸ”¹ **Sauvegarder les tweets invalides pour analyse future**
df_invalid.to_csv("dataset/ignored_tweets.csv", index=False)

print(f"âš  {len(df_invalid)} tweets ignorÃ©s car ils contiennent des valeurs NaN.")
print(f"âœ… {len(df_valid)} tweets valides vont Ãªtre insÃ©rÃ©s en base.")

# Diviser les donnÃ©es en 66% pour l'entraÃ®nement et 33% pour le rÃ©entraÃ®nement
df_train, df_retrain = train_test_split(df_valid, test_size=0.33, random_state=42)

# Connexion Ã  MySQL
conn = mysql.connector.connect(
    host="localhost",
    user="user",
    password="password",
    database="sentiment_analysis"
)
cursor = conn.cursor()

# InsÃ©rer uniquement les 66% des tweets pour l'entraÃ®nement
insert_query = "INSERT INTO tweet (text, positive, negative) VALUES (%s, %s, %s)"
data_to_insert = list(zip(df_train['clean_text'], df_train['positive'], df_train['negative']))
cursor.executemany(insert_query, data_to_insert)
conn.commit()

# Fermer la connexion
cursor.close()
conn.close()

# Sauvegarder les 33% restants dans un fichier CSV pour le rÃ©entraÃ®nement futur
df_retrain.to_csv("dataset/retrain_tweets.csv", index=False)

print(f"âœ… {len(df_train)} tweets insÃ©rÃ©s dans la base de donnÃ©es.")
print(f"âœ… {len(df_retrain)} tweets sauvegardÃ©s pour le rÃ©entraÃ®nement futur.")
print(f"ğŸ“ Les tweets ignorÃ©s sont enregistrÃ©s dans 'dataset/ignored_tweets.csv'.")
